{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcms_processing_functions import *\n",
    "from output_dataframes import *\n",
    "\n",
    "def process_compound_data(file_path, weighting_scheme):\n",
    "    \"\"\"\n",
    "    Reads an Excel file, processes each compound, and stores processed data in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the Excel file containing raw data.\n",
    "    - weighting_scheme (str): Weighting scheme for linear regression of calibration curve.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with processed data for each compound, including calibration, concentrations, QC, and replicate statistics.\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    compound_dict = {}\n",
    "\n",
    "    # Process each compound separately\n",
    "    for compound, data in df.groupby('Compound'):\n",
    "        compound_name = compound.split('_')[-1]\n",
    "        \n",
    "        # Perform calibration and calculate concentrations\n",
    "        cal_std_df, LOQ = process_calibration(data)\n",
    "        cal_curve = get_calibration_curve(cal_std_df, LOQ, weighting_scheme)\n",
    "        samples_df = process_samples(data)\n",
    "        cal_std_df = calculate_concentrations(cal_std_df, LOQ, cal_curve)\n",
    "        samples_df = calculate_concentrations(samples_df, LOQ, cal_curve)\n",
    "        \n",
    "        # Modify 'Sample Type' for categorization\n",
    "        samples_df = sample_type(samples_df)\n",
    "        \n",
    "        # Perform blank subtraction\n",
    "        samples_df = subtraction(samples_df)\n",
    "\n",
    "        # Perform QC calculations\n",
    "        dup_precision_df = duplication_comparison(samples_df)\n",
    "        spike_precision_df = spike_comparison(samples_df)\n",
    "        qc_precision_df = qc_comparison(samples_df, cal_std_df)\n",
    "\n",
    "        # Store all processed data in the compound dictionary\n",
    "        compound_dict[compound_name] = {\n",
    "            'Cal Std': cal_std_df,\n",
    "            'Sample': samples_df,\n",
    "            'LOQ': LOQ,\n",
    "            'Regression results': cal_curve,\n",
    "            'Duplication Precision': dup_precision_df,\n",
    "            'Spike Precision': spike_precision_df,\n",
    "            'QC Precision': qc_precision_df\n",
    "        }\n",
    "\n",
    "    return compound_dict\n",
    "\n",
    "def filter_compounds(compound_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Filters out isotopically-labelled compounds from the compound dictionary based on their names.\n",
    "    Excludes compounds containing '13C2', starting with 'M' or 'd' followed by a digit,\n",
    "    or matching 'PFHxS(O18)2'.\n",
    "\n",
    "    Parameters:\n",
    "    - compound_dict (dict): A dictionary of compounds with associated data.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing only the filtered compounds.\n",
    "    \"\"\"\n",
    "    filtered_compounds = {\n",
    "        compound: data\n",
    "        for compound, data in compound_dict.items()\n",
    "        if not (\n",
    "            (\"13C2\" in compound) or\n",
    "            (compound.startswith(\"M\") and compound[1].isdigit()) or\n",
    "            (compound.startswith(\"d\") and compound[1].isdigit()) or\n",
    "            (compound == \"PFHxS(O18)2\") or\n",
    "            (compound == \"MFOUEA\") or \n",
    "            (compound == \"PFHxDA\") or \n",
    "            (compound == \"PFODA\") or \n",
    "            (compound == \"FMSA\") or \n",
    "            (compound == \"FESA\") or \n",
    "            (compound == \"FPrSA\") or \n",
    "            (compound == \"FHpSA\")\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return filtered_compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Insert your input Excel spreadsheet filepath below ####\n",
    "file_path = '/Users/ethansontarp/Library/CloudStorage/OneDrive-HarvardUniversity/Sunderland Lab/Projects/Undergraduate Projects/02 Alaskan Community Waters/Unprocessed Data/Alaska_Community_LLE_2_Renamed.xlsx'\n",
    "\n",
    "#### Define your desired weighting scheme for the linear regression of the calibration curve\n",
    "    ## Options: 'standard', for equal weighting, and 'inverse' for 1/X weighting\n",
    "weighting_scheme = 'inverse'\n",
    "\n",
    "compound_dict = process_compound_data(file_path, weighting_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved to '/Users/ethansontarp/Desktop/test.xlsx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethansontarp/Library/CloudStorage/OneDrive-HarvardUniversity/Sunderland Lab/Programming/lcms-processing/output_dataframes.py:121: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_smp_concentrations_wide = (df_smp_concentrations_wide.reindex(columns=compound_order).astype(\"object\").fillna(\"<LOQ\").infer_objects(copy=False))\n"
     ]
    }
   ],
   "source": [
    "#### Insert your output Excel spreadsheet filepath below ####\n",
    "output_filename = \"/Users/ethansontarp/Desktop/test.xlsx\"\n",
    "\n",
    "filtered_compounds = filter_compounds(compound_dict)\n",
    "# Generate DataFrames\n",
    "df_loq = create_loq_dataframe(filtered_compounds)\n",
    "df_peak_area = create_peak_area_dataframe(compound_dict)\n",
    "df_raw_concentrations = create_raw_concentrations_dataframe(filtered_compounds)\n",
    "df_smp_concentrations = create_smp_concentrations_dataframe(filtered_compounds)\n",
    "df_duplication = create_dup_prec_dataframe(filtered_compounds)\n",
    "df_spike = create_spike_prec_dataframe(filtered_compounds)\n",
    "df_qc = create_qc_prec_dataframe(filtered_compounds)\n",
    "\n",
    "with pd.ExcelWriter(output_filename, engine=\"xlsxwriter\") as writer:\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Define the header format\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'bg_color': '#C1E1FF',\n",
    "        'border': 1\n",
    "    })\n",
    "\n",
    "    # Write each sheet and format the first row headers\n",
    "    if not df_loq.empty:\n",
    "        df_loq.to_excel(writer, sheet_name=\"LOQ\", index=False, header=False, startrow=1)  # Leave space for custom headers\n",
    "        worksheet = writer.sheets[\"LOQ\"]\n",
    "        # Write and format headers manually\n",
    "        for col_num, value in enumerate(df_loq.columns):\n",
    "            worksheet.write(0, col_num, value, header_format)  # Write header with formatting\n",
    "\n",
    "    if not df_peak_area.empty:\n",
    "        df_peak_area.to_excel(writer, sheet_name=\"Peak Area\", index=False, header=False, startrow=1) \n",
    "        worksheet = writer.sheets[\"Peak Area\"]\n",
    "        for col_num, value in enumerate(df_peak_area.columns):\n",
    "            worksheet.write(0, col_num, value, header_format) \n",
    "\n",
    "    if not df_raw_concentrations.empty:\n",
    "        df_raw_concentrations.to_excel(writer, sheet_name=\"Pre-Subtracted Concentrations\", index=False, header=False, startrow=1)  \n",
    "        worksheet = writer.sheets[\"Pre-Subtracted Concentrations\"]\n",
    "        for col_num, value in enumerate(df_raw_concentrations.columns):\n",
    "            worksheet.write(0, col_num, value, header_format) \n",
    "\n",
    "    if not df_smp_concentrations.empty:\n",
    "        df_smp_concentrations.to_excel(writer, sheet_name=\"Blank-Subtracted Concentrations\", index=False, header=False, startrow=1)\n",
    "        worksheet = writer.sheets[\"Blank-Subtracted Concentrations\"]\n",
    "        for col_num, value in enumerate(df_smp_concentrations.columns):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "    if not df_duplication.empty:\n",
    "        df_duplication.to_excel(writer, sheet_name=\"Duplication Precision\", index=False, header=False, startrow=1)\n",
    "        worksheet = writer.sheets[\"Duplication Precision\"]\n",
    "        for col_num, value in enumerate(df_duplication.columns):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "    if not df_spike.empty:\n",
    "        df_spike.to_excel(writer, sheet_name=\"Spike Precision\", index=False, header=False, startrow=1)\n",
    "        worksheet = writer.sheets[\"Spike Precision\"]\n",
    "        for col_num, value in enumerate(df_spike.columns):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "    if not df_qc.empty:\n",
    "        df_qc.to_excel(writer, sheet_name=\"QC Precision\", index=False, header=False, startrow=1)\n",
    "        worksheet = writer.sheets[\"QC Precision\"]\n",
    "        for col_num, value in enumerate(df_qc.columns):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "print(f\"Excel file saved to '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs109a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
